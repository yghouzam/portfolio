{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential, Input\n",
    "from keras.layers import Bidirectional, CuDNNLSTM, Embedding, Dropout, Dense,TimeDistributed, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please donwload ner_dataset.csv from https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "df = pd.read_csv(\"ner_dataset.csv\",sep=\",\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are vertically stacked and we have only the first row of each sentence that is filled. So we have to fill each of the NaN rows with their corresponding sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence attribution\n",
    "df[\"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentence and tag sequences.\n",
    "agg_func = lambda x : (x['Word'].values.tolist(), x['Tag'].values.tolist())\n",
    "sequences_tags = df.groupby(\"Sentence #\").apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent[0] for sent in sequences_tags]\n",
    "tags = [sent[1] for sent in sequences_tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to keep ever characters from the sentences.\n",
    "tokenizer_sent = Tokenizer(filters='')\n",
    "tokenizer_sent.fit_on_texts(sentences)\n",
    "index_word = tokenizer_sent.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the endpad\n",
    "index_word.update({0:\"ENDPAD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seq = tokenizer_sent.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tags tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to keep ever characters from the tags.\n",
    "tokenizer_tags = Tokenizer(filters='')\n",
    "tokenizer_tags.fit_on_texts(tags)\n",
    "index_tags = tokenizer_tags.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tags.update({0:\"ENDPAD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_size = len(index_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_seq = tokenizer_tags.texts_to_sequences(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the max sentence and tag length\n",
    "max_len_seq = max([len(i) for i in sent_seq])\n",
    "max_len_tag = max([len(i) for i in tags_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sent_seq,padding='post',value=0, maxlen=max_len_seq)\n",
    "y = pad_sequences(tags_seq,padding='post',value=0, maxlen=max_len_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels transformed as categorical hot encoded vectors (i.e [[2,6,0]] -> [[0,0,1,0,0,0],[0,0,0,0,0,0,1],[1,0,0,0,0,0]] )\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 104, 100)          3181800   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 104, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 104, 50)           25400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 104, 18)           918       \n",
      "=================================================================\n",
      "Total params: 3,208,118\n",
      "Trainable params: 3,208,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = 100, input_length = max_len_seq))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(CuDNNLSTM(25,return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tags_size,activation = 'softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers :\n",
    "     - Embedding , i embedded the sentences (M, max length = 104) within a dimension D of 100.\n",
    "     \n",
    "     - Dropout , used to avoid overfitting (0.3 is the dropout rate) every epochs 30% of the connexions between LSTM and the embedding layer are turned off randomly -> forces the network to find recurrent paths.\n",
    "     \n",
    "     - LSTM, i used LSTM layer since it is suitable for sequence tasks and allows to 'remember' the context words, param return_sequences = True makes the output of a dimension (None, M, N) instead of (None, N) N is the number of units of an LSTM (here 2 x 25 , since we used Bidirectional layer). We need every sequence time (M) outputs from the LSTM, we will predict a named entity for each of them.\n",
    "     \n",
    "     - CuDNNLSTM, this is an LSTM layer but optimized for GPU computing (CuDNN) ultra fast\n",
    "     \n",
    "     - Bidirectional , better when you have a sequence task. Reads sequence in the two directions to get the meaning from every direction.\n",
    "     \n",
    "     - Dense, final layer is a fully connected layer with a softmax activation and the number of tags classes to output.\n",
    "     \n",
    "     - TimeDistributed, as we want to predict every named entity for every word of our sequence we need to specify it using the TimeDistributed layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25705 samples, validate on 6427 samples\n",
      "Epoch 1/5\n",
      "25705/25705 [==============================] - 8s 329us/step - loss: 0.4903 - acc: 0.9221 - val_loss: 0.1486 - val_acc: 0.9677\n",
      "Epoch 2/5\n",
      "25705/25705 [==============================] - 3s 131us/step - loss: 0.1205 - acc: 0.9680 - val_loss: 0.1011 - val_acc: 0.9694\n",
      "Epoch 3/5\n",
      "25705/25705 [==============================] - 3s 131us/step - loss: 0.0845 - acc: 0.9775 - val_loss: 0.0727 - val_acc: 0.9818\n",
      "Epoch 4/5\n",
      "25705/25705 [==============================] - 3s 131us/step - loss: 0.0602 - acc: 0.9848 - val_loss: 0.0553 - val_acc: 0.9861\n",
      "Epoch 5/5\n",
      "25705/25705 [==============================] - 3s 131us/step - loss: 0.0457 - acc: 0.9882 - val_loss: 0.0458 - val_acc: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a4997bfd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs= 5, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =  np.argmax(y_pred,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decode(seq_words,seq_tag,index_words,index_tags):\n",
    "    for idx_w,idx_t in zip(seq_words,seq_tag):\n",
    "        w = index_words[idx_w]\n",
    "        t = index_tags[idx_t]\n",
    "        if w == \"ENDPAD\":\n",
    "            break\n",
    "        print(f\"{w:{30}} {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the                            o\n",
      "pact                           o\n",
      "was                            o\n",
      "initially                      o\n",
      "approved                       o\n",
      "after                          o\n",
      "discussions                    o\n",
      "between                        o\n",
      "president                      b-per\n",
      "bush                           i-per\n",
      "and                            o\n",
      "peruvian                       b-gpe\n",
      "president                      b-per\n",
      "alan                           i-per\n",
      "garcia                         i-per\n",
      ",                              o\n",
      "but                            o\n",
      "democrats                      o\n",
      "in                             o\n",
      "congress                       b-org\n",
      "forced                         o\n",
      "u.s.                           b-geo\n",
      "officials                      o\n",
      "to                             o\n",
      "reopen                         o\n",
      "negotiations                   o\n",
      "and                            o\n",
      "add                            o\n",
      "stronger                       o\n",
      "labor                          o\n",
      "and                            o\n",
      "environmental                  o\n",
      "provisions                     o\n",
      ".                              o\n"
     ]
    }
   ],
   "source": [
    "print_decode(X_test[2],pred[2],index_word,index_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ['B-GEO','B-TIM','B-ORG','I-PER','B-PER','I-ORG','B-GPE','I-GEO','I-TIM','B-ART','B-EVE',\\\n",
    "                'I-ART','I-EVE','B-NAT','I-GPE','I-NAT',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#e6fc9c\",\"#fcb09c\",\"#73534a\",\"#aa9cfc\",\"#aa9cfc\",\n",
    "          \"#8e15a1\",\"#15a135\",\"#a19f15\",\"#16dfe2\",\"#162fe2\",\"#ffa46d\",\n",
    "          \"#b4ff6d\",\"#b86dff\",\"#ff6d6d\",\"#d3ff6d\",\"#ffce6d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"ents\": entities, \"colors\" : dict(zip(entities,colors))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_NER(seq_words, seq_tag, index_words, index_tags, options = options):\n",
    "    text = \"\"\n",
    "    ents = []\n",
    "    title = None\n",
    "    seq_tag = zip(seq_words,seq_tag)\n",
    "    for i, (idx_w, idx_t) in enumerate(seq_tag):\n",
    "        w = index_words[idx_w]\n",
    "        t = index_tags[idx_t]\n",
    "        \n",
    "        if w == \"ENDPAD\":\n",
    "            break\n",
    "        \n",
    "        start = len(text)\n",
    "        text += w + ' '\n",
    "        end = len(text)\n",
    "        label = t.upper()\n",
    "        if t != 'o':\n",
    "            ents.append({'start':start,'end':end, 'label':label})\n",
    "    \n",
    "    res_dict = {\"text\":text,\"ents\":ents,\"title\":title}\n",
    "    displacy.render(res_dict, style=\"ent\", manual = True, jupyter = True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">the pact was initially approved after discussions between \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    president \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    bush \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-PER</span>\n",
       "</mark>\n",
       "and \n",
       "<mark class=\"entity\" style=\"background: #15a135; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    peruvian \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GPE</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    president \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    alan \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-PER</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    garcia \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-PER</span>\n",
       "</mark>\n",
       ", but democrats in \n",
       "<mark class=\"entity\" style=\"background: #73534a; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    congress \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       "forced \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    u.s. \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       "officials to reopen negotiations and add stronger labor and environmental provisions . </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_NER(X_test[2],pred[2],index_word,index_tags,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">officials estimate that some 5,00,000 people living in latin \n",
       "<mark class=\"entity\" style=\"background: #15a135; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    american \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GPE</span>\n",
       "</mark>\n",
       "countries such as \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cuba \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    argentina \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mexico \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    venezuela \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chile \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       "and \n",
       "<mark class=\"entity\" style=\"background: #e6fc9c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    uruguay \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-GEO</span>\n",
       "</mark>\n",
       "are eligible for citizenship . </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_NER(X_test[10],pred[10],index_word,index_tags,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
